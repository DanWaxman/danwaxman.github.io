<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Dan Waxman</title> <meta name="author" content="Dan Waxman"> <meta name="description" content="My personal website. Words, and stuff. "> <meta name="keywords" content="causality, bayesian-learning, statistics, machine-learning"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.ico?4faf96c0b05f32ce9ddf8b975e1d9958"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://danwaxman.github.io/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/research/">research</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Dan</span> Waxman </h1> <p class="desc">PhD Candidate, Stony Brook University</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/prof_pic-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/prof_pic-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/prof_pic-1400.webp"></source> <img src="/assets/img/prof_pic.jpg?167f32ca1e5f83724600f6bf97136966" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="prof_pic.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="more-info"> <p>Department of Electrical and Computer Engineering</p> <p>Stony Brook University</p> <p>Stony Brook, New York, USA</p> </div> </div> <div class="clearfix"> <p>I’m a fifth-year PhD student at <a href="https://www.stonybrook.edu/" rel="external nofollow noopener" target="_blank">Stony Brook University</a> working with <a href="https://sites.google.com/stonybrook.edu/petardjuric/" rel="external nofollow noopener" target="_blank">Petar Djurić</a>. During Summer 2025, I was a research intern <a href="https://basis.ai" rel="external nofollow noopener" target="_blank">Basis</a>, where I worked on problems in applied Bayesian ML and causality. I’m broadly interested in Bayesian machine learning and causality, and have worked more specifically in sequential and online learning, Bayesian ensemble algorithms, and differentiable causal discovery. I’m particularly interested in advancing theoretical methods in pursuit of applications, and am a member of the <a href="https://sw-ifl.asu.edu/people" rel="external nofollow noopener" target="_blank">Southwest Integrated Field Laboratory</a>, where I’ve worked with <a href="https://katialamer.weebly.com/" rel="external nofollow noopener" target="_blank">Katia Lamer</a> in applying ML techniques to applied experimental design problems. You can find more about my research interests in publications on my <a href="research">research page</a>.</p> <p>Prior to graduate school, I also completed my undergrad at Stony Brook in math and statistics. At Stony Brook, I’ve served as a Senator in the <a href="https://www.stonybrookgso.org" rel="external nofollow noopener" target="_blank">SBU Graduate Student Organization</a>, the Graduate Council, and was a member of the <a href="https://www.stonybrook.edu/commcms/strategicplan/committee.php" rel="external nofollow noopener" target="_blank">SBU Strategic Planning Steering Committee</a>. For the past several years, I’ve participated in the Directed Reading Programs of <a href="https://sites.google.com/view/cunydrp/home" rel="external nofollow noopener" target="_blank">CUNY</a> and <a href="https://sites.google.com/stonybrook.edu/drp" rel="external nofollow noopener" target="_blank">SBU</a>, where I mentor students in semester-long reading projects in math, machine learning, and statistics.</p> </div> <h2><a href="/news/" style="color: inherit;">news</a></h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Oct 10, 2025</th> <td> I had a great time as a research intern at <a href="https://basis.ai" rel="external nofollow noopener" target="_blank">Basis</a> this summer, where I worked with Rafal Urbaniak and Jack Feser on problems in applied Bayesian ML and causality. I’m super excited to join back full-time as a postdoctoral fellow in January 2026, working on tools for dynamical systems with Matt Levine at Basis and Youssef Marzouk at MIT! </td> </tr> <tr> <th scope="row">Dec 7, 2024</th> <td> <a href="https://openreview.net/forum?id=Bj2CpB9Dey" rel="external nofollow noopener" target="_blank">Tangent Space Causal Inference</a> was accepted as a poster at NeurIPS 2024. See you in Vancouver! </td> </tr> </table> </div> </div> <h2><a href="/publications/" style="color: inherit;">selected publications</a></h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="llorente2025robust" class="col-sm-8"> <div class="title">Robust, Online, and Adaptive Decentralized Gaussian Processes</div> <div class="author"> Fernando Llorente, <em>Daniel Waxman</em>, Sanket Jantre, Nathan M. Urban, and Susan E. Minkoff</div> <div class="periodical"> <em></em> 2025 </div> <div class="periodical"> Submitted </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Gaussian processes (GPs) offer a flexible, uncertainty-aware framework for modeling complex signals, but scale cubically with data, assume static targets, and are brittle to outliers, limiting their applicability in large-scale problems with dynamic and noisy environments. Recent work introduced decentralized random Fourier feature Gaussian processes (DRFGP), an online and distributed algorithm that casts GPs in an information-filter form, enabling exact sequential inference and fully distributed computation without reliance on a fusion center. In this paper, we extend DRFGP along two key directions: first, by introducing a robust-filtering update that downweights the impact of atypical observations; and second, by incorporating a dynamic adaptation mechanism that adapts to time-varying functions. The resulting algorithm retains the recursive information-filter structure while enhancing stability and accuracy. We demonstrate its effectiveness on a large-scale Earth system application, underscoring its potential for in-situ modeling.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">llorente2025robust</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Llorente, Fernando and Waxman, Daniel and Jantre, Sanket and Urban, Nathan M. and Minkoff, Susan E.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Robust, Online, and Adaptive Decentralized Gaussian Processes}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Submitted}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="waxman2025mil" class="col-sm-8"> <div class="title">Designing an Optimal Sensor Network via Minimizing Information Loss</div> <div class="author"> <em>Daniel Waxman</em>, Fernando Llorente, <a href="https://katialamer.weebly.com/" rel="external nofollow noopener" target="_blank">Katia Lamer</a>, and <a href="https://sites.google.com/stonybrook.edu/petardjuric/" rel="external nofollow noopener" target="_blank">Petar M. Djurić</a> </div> <div class="periodical"> <em></em> 2025 </div> <div class="periodical"> Submitted. </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Optimal experimental design is a classic topic in statistics, with many well-studied problems, applications, and solutions. The design problem we study is the placement of sensors to monitor spatiotemporal processes, explicitly accounting for the temporal dimension in our modeling and optimization. We observe that recent advancements in computational sciences often yield large datasets based on physics-based simulations, which are rarely leveraged in experimental design. We introduce a novel model-based sensor placement criterion, along with a highly-efficient optimization algorithm, which integrates physics-based simulations and Bayesian experimental design principles to identify sensor networks that “minimize information loss” from simulated data. Our technique relies on sparse variational inference and Gauss-Markov priors, and thus may adapt many techniques from Bayesian experimental design. We validate our method through a case study monitoring air temperature in Phoenix, Arizona, using state-of-the-art physics-based simulations. Our results show our framework to be superior to random or quasi-random sampling, particularly with a limited number of sensors. We conclude by discussing practical considerations and implications of our framework, including more complex modeling tools and real-world deployments.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">waxman2025mil</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Waxman, Daniel and Llorente, Fernando and Lamer, Katia and Djurić, Petar {M.}}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Designing an Optimal Sensor Network via Minimizing Information Loss}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Submitted.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="waxman2025obs" class="col-sm-8"> <div class="title">Bayesian Ensembling: Insights from Online Optimization and Empirical Bayes</div> <div class="author"> <em>Daniel Waxman</em>, Fernando Llorente, and <a href="https://sites.google.com/stonybrook.edu/petardjuric/" rel="external nofollow noopener" target="_blank">Petar M. Djurić</a> </div> <div class="periodical"> <em></em> 2025 </div> <div class="periodical"> Submitted. </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/https://arxiv.org/abs/2505.15638" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>We revisit the classical problem of Bayesian ensembles and address the challenge of learning optimal combinations of Bayesian models in an online, continual learning setting. To this end, we reinterpret existing approaches such as Bayesian model averaging (BMA) and Bayesian stacking through a novel empirical Bayes lens, shedding new light on the limitations and pathologies of BMA. Further motivated by insights from online optimization, we propose Online Bayesian Stacking (OBS), a method that optimizes the log-score over predictive distributions to adaptively combine Bayesian models. A key contribution of our work is establishing a novel connection between OBS and portfolio selection, bridging Bayesian ensemble learning with a rich, well-studied theoretical framework that offers efficient algorithms and extensive regret analysis. We further clarify the relationship between OBS and online BMA, showing that they optimize related but distinct cost functions. Through theoretical analysis and empirical evaluation, we identify scenarios where OBS outperforms online BMA and provide principled guidance on when practitioners should prefer one approach over the other.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">waxman2025obs</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Waxman, Daniel and Llorente, Fernando and Djurić, Petar {M.}}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Bayesian Ensembling: Insights from Online Optimization and Empirical Bayes}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Submitted.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ICASSP ’25</abbr></div> <div id="llorente2025decentralized" class="col-sm-8"> <div class="title">Decentralized Online Ensembles of Gaussian Processes for Multi-Agent Systems</div> <div class="author"> Fernando Llorente*, <em>Daniel Waxman*</em>, and <a href="https://sites.google.com/stonybrook.edu/petardjuric/" rel="external nofollow noopener" target="_blank">Petar M. Djurić</a> </div> <div class="periodical"> <em>In 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/https://arxiv.org/abs/2502.05301" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">llorente2025decentralized</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Llorente*, Fernando and Waxman*, Daniel and Djurić, Petar {M.}}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Decentralized Online Ensembles of Gaussian Processes for Multi-Agent Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS ’24</abbr></div> <div id="butler2024tangent" class="col-sm-8"> <div class="title">Tangent Space Causal Inference: Leveraging Vector Fields for Causal Discovery in Dynamical Systems</div> <div class="author"> <a href="https://sites.google.com/view/kurt-butler/home?pli=1" rel="external nofollow noopener" target="_blank">Kurt Butler*</a>, <em>Daniel Waxman*</em>, and <a href="https://sites.google.com/stonybrook.edu/petardjuric/" rel="external nofollow noopener" target="_blank">Petar M. Djurić</a> </div> <div class="periodical"> <em></em> 2024 </div> <div class="periodical"> Advances in Neural Information Processing Systems (NeurIPS) 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/https://arxiv.org/abs/2410.23499" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openreview.net/forum?id=Bj2CpB9Dey" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/KurtButler/tangentspaces" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Causal discovery with time series data remains a challenging yet increasingly important task across many scientific domains. Convergent cross mapping (CCM) and related methods have been proposed to study time series that are generated by dynamical systems, where traditional approaches like Granger causality are unreliable. However, CCM often yields inaccurate results depending upon the quality of the data. We propose the Tangent Space Causal Inference (TSCI) method for detecting causalities in dynamic systems. TSCI works by considering vector fields as explicit representations of the systems’ dynamics and checks for the degree of synchronization between the learned vector fields. The TSCI approach is model-agnostic and can be used as a drop-in replacement for CCM and its generalizations. We present both a basic TSCI algorithm, which is lightweight and more effective than the basic CCM algorithm, as well as augmented versions of TSCI that leverage the expressive power of latent variable models and deep learning. We validate our theory on standard systems, and we demonstrate improved causal inference performance across a number of benchmarks.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">butler2024tangent</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Butler*, Kurt and Waxman*, Daniel and Djurić, Petar {M.}}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Tangent Space Causal Inference: Leveraging Vector Fields for Causal Discovery in Dynamical Systems}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems (NeurIPS) 2024}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">TMLR</abbr></div> <div id="waxman2024doebe" class="col-sm-8"> <div class="title">Dynamic Online Ensembles of Basis Expansions</div> <div class="author"> <em>Daniel Waxman</em>, and <a href="https://sites.google.com/stonybrook.edu/petardjuric/" rel="external nofollow noopener" target="_blank">Petar M. Djurić</a> </div> <div class="periodical"> <em>Transactions on Machine Learning Research (TMLR)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/http://arxiv.org/abs/2405.01365" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openreview.net/forum?id=aVOzWH1Nc5" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/DanWaxman/DynamicOnlineBasisExpansions" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Practical Bayesian learning often requires (1) online inference, (2) dynamic models, and (3) ensembling over multiple different models. Recent advances have shown how to use random feature approximations to achieve scalable, online ensembling of Gaussian processes with desirable theoretical properties and fruitful applications. One key to these methods’ success is the inclusion of a random walk on the model parameters, which makes models dynamic. We show that these methods can be generalized easily to any basis expansion model and that using alternative basis expansions, such as Hilbert space Gaussian processes, often results in better performance. To simplify the process of choosing a specific basis expansion, our method’s generality also allows the ensembling of several entirely different models, for example, a Gaussian process and polynomial regression. Finally, we propose a novel method to ensemble static and dynamic models together.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">waxman2024doebe</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Waxman, Daniel and Djurić, Petar {M.}}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Dynamic Online Ensembles of Basis Expansions}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Transactions on Machine Learning Research (TMLR)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">OJ-SP</abbr></div> <div id="waxman2024dagmadce" class="col-sm-8"> <div class="title">DAGMA-DCE: Interpretable, Non-Parametric Differentiable Causal Discovery</div> <div class="author"> <em>Daniel Waxman</em>, <a href="https://sites.google.com/view/kurt-butler/home?pli=1" rel="external nofollow noopener" target="_blank">Kurt Butler</a>, and <a href="https://sites.google.com/stonybrook.edu/petardjuric/" rel="external nofollow noopener" target="_blank">Petar M. Djurić</a> </div> <div class="periodical"> <em>IEEE Open Journal of Signal Processing</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2401.02930" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/10384714" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/DanWaxman/DAGMA-DCE" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>We introduce Dagma-DCE, an interpretable and model-agnostic scheme for differentiable causal discovery. Current non- or over-parametric methods in differentiable causal discovery use opaque proxies of “independence” to justify the inclusion or exclusion of a causal relationship. We show theoretically and empirically that these proxies may be arbitrarily different than the actual causal strength. Juxtaposed with existing differentiable causal discovery algorithms, Dagma-DCE uses an interpretable measure of causal strength to define weighted adjacency matrices. In a number of simulated datasets, we show our method achieves state-of-the-art level performance. We additionally show that Dagma-DCE allows for principled thresholding and sparsity penalties by domain-experts. The code for our method is available open-source at https://github.com/DanWaxman/DAGMA-DCE, and can easily be adapted to arbitrary differentiable models.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">waxman2024dagmadce</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Waxman, Daniel and Butler, Kurt and Djurić, Petar {M.}}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{DAGMA-DCE: Interpretable, Non-Parametric Differentiable Causal Discovery}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{5}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Open Journal of Signal Processing}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{393-401}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/OJSP.2024.3351593}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%64%61%6E%69%65%6C.%77%61%78%6D%61%6E@%73%74%6F%6E%79%62%72%6F%6F%6B.%65%64%75" title="email"><i class="fas fa-envelope"></i></a> <a href="https://orcid.org/0009-0004-0168-5547#%20your%20ORCID%20ID" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=_QM1YGQAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/danwaxman" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a> </div> <div class="contact-note"> </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Dan Waxman. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: November 13, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-L64ZMP0TLH"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-L64ZMP0TLH");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>